{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "b25c492f-466a-4664-a1fb-74f457c08cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changes in Mean and Standard Deviation Before and After Cleaning:\n",
      "\n",
      "                    Mean_Before_Cleaning  Mean_After_Cleaning  Delta_Mean  \\\n",
      "seats                          32.100457            31.936137   -0.164320   \n",
      "sq_pm                           0.128882             0.127726   -0.001156   \n",
      "election_year                1998.307458          1998.372274    0.064816   \n",
      "miw_new                         8.864536             8.247664   -0.616872   \n",
      "banzhaf                         0.129328             0.130372    0.001044   \n",
      "shapley                         0.129337             0.130400    0.001063   \n",
      "splus                           0.129289             0.130466    0.001177   \n",
      "caretaker                     -15.158295             0.062305   15.220601   \n",
      "cabinet_party                   0.350076             0.350467    0.000391   \n",
      "prime_minister                  0.127854             0.129283    0.001430   \n",
      "cabinet_seats                   2.304414             2.302181   -0.002233   \n",
      "total_cabinet_size             19.003044            18.850467   -0.152577   \n",
      "party_count                     9.207002             8.984424   -0.222578   \n",
      "cab_count                       3.010654             2.975078   -0.035577   \n",
      "seats_share                    12.813260            12.965512    0.152252   \n",
      "enpp                            4.915088             4.867010   -0.048078   \n",
      "mingov                          0.324201             0.331776    0.007575   \n",
      "bicameral                       0.544901             0.534268   -0.010633   \n",
      "largest_parl                    0.130898             0.132399    0.001501   \n",
      "largest_cab                     0.132420             0.133956    0.001536   \n",
      "seats_total                   262.339422           254.515576   -7.823845   \n",
      "miw_proportion                  0.129376             0.130568    0.001192   \n",
      "cabinet_proportion              0.129376             0.129983    0.000607   \n",
      "seats_proportion                0.129376             0.130927    0.001551   \n",
      "W                             131.905632           127.989097   -3.916535   \n",
      "A                               0.000000             0.000000    0.000000   \n",
      "B                               0.398782             0.406542    0.007760   \n",
      "B_star                          0.057839             0.059190    0.001351   \n",
      "C                               0.048706             0.048287   -0.000420   \n",
      "D                               0.249619             0.255452    0.005832   \n",
      "E                               0.302892             0.289720   -0.013172   \n",
      "country_dummy1                  0.047184             0.048287    0.001102   \n",
      "country_dummy2                  0.120244             0.123053    0.002809   \n",
      "country_dummy3                  0.050228             0.049844   -0.000384   \n",
      "country_dummy4                  0.085236             0.087227    0.001991   \n",
      "country_dummy5                  0.091324             0.093458    0.002134   \n",
      "country_dummy6                  0.080670             0.080997    0.000327   \n",
      "country_dummy7                  0.057839             0.059190    0.001351   \n",
      "country_dummy8                  0.141553             0.124611   -0.016942   \n",
      "country_dummy9                  0.044140             0.045171    0.001031   \n",
      "country_dummy10                 0.105023             0.107477    0.002454   \n",
      "country_dummy11                 0.068493             0.070093    0.001600   \n",
      "country_dummy12                 0.033486             0.034268    0.000782   \n",
      "country_dummy13                 0.074581             0.076324    0.001743   \n",
      "\n",
      "                    Std_Before_Cleaning  Std_After_Cleaning   Delta_Std  \n",
      "seats                         46.440287           46.185044   -0.255243  \n",
      "sq_pm                          0.335330            0.334045   -0.001285  \n",
      "election_year                  7.288470            7.326573    0.038103  \n",
      "miw_new                       18.576594           16.192081   -2.384513  \n",
      "banzhaf                        0.144730            0.144969    0.000239  \n",
      "shapley                        0.140964            0.141112    0.000148  \n",
      "splus                          0.140634            0.140914    0.000280  \n",
      "caretaker                    390.100596            0.241898 -389.858698  \n",
      "cabinet_party                  0.477357            0.477488    0.000131  \n",
      "prime_minister                 0.334181            0.335775    0.001594  \n",
      "cabinet_seats                  4.174019            4.177306    0.003287  \n",
      "total_cabinet_size             4.828143            4.731091   -0.097052  \n",
      "party_count                    3.559993            3.197075   -0.362918  \n",
      "cab_count                      1.450886            1.440229   -0.010656  \n",
      "seats_share                   12.112704           12.137074    0.024371  \n",
      "enpp                           1.587204            1.557461   -0.029742  \n",
      "mingov                         0.468432            0.471218    0.002786  \n",
      "bicameral                      0.498359            0.499213    0.000854  \n",
      "largest_parl                   0.337546            0.339188    0.001642  \n",
      "largest_cab                    0.339205            0.340871    0.001666  \n",
      "seats_total                  187.949004          182.083309   -5.865696  \n",
      "miw_proportion                 0.108112            0.107738   -0.000374  \n",
      "cabinet_proportion             0.226728            0.227945    0.001217  \n",
      "seats_proportion               0.123545            0.123822    0.000278  \n",
      "W                             93.954518           91.011999   -2.942519  \n",
      "A                              0.000000            0.000000    0.000000  \n",
      "B                              0.490021            0.491571    0.001550  \n",
      "B_star                         0.233616            0.236164    0.002548  \n",
      "C                              0.215417            0.214538   -0.000879  \n",
      "D                              0.433123            0.436455    0.003332  \n",
      "E                              0.459859            0.453986   -0.005873  \n",
      "country_dummy1                 0.212194            0.214538    0.002344  \n",
      "country_dummy2                 0.325494            0.328754    0.003260  \n",
      "country_dummy3                 0.218582            0.217793   -0.000789  \n",
      "country_dummy4                 0.279445            0.282388    0.002943  \n",
      "country_dummy5                 0.288289            0.291300    0.003011  \n",
      "country_dummy6                 0.272535            0.273043    0.000508  \n",
      "country_dummy7                 0.233616            0.236164    0.002548  \n",
      "country_dummy8                 0.348856            0.330534   -0.018322  \n",
      "country_dummy9                 0.205563            0.207842    0.002279  \n",
      "country_dummy10                0.306816            0.309960    0.003143  \n",
      "country_dummy11                0.252783            0.255504    0.002721  \n",
      "country_dummy12                0.180038            0.182058    0.002021  \n",
      "country_dummy13                0.262915            0.265723    0.002808  \n",
      "\n",
      "Final dataset shape: (642, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n",
      "/var/folders/z6/93vk8zs14dn7td0ly8dm9vz00000gn/T/ipykernel_80030/1371269647.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = df[col].astype(int)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --------------------------------------------Data Cleaning & Preprocessing--------------------------------------------------------\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"/Users/jz/Desktop/ML Final/class_final_proportion.csv\")\n",
    "\n",
    "# Drop rows with missing DV values\n",
    "df1 = df[df['cabinet_proportion'].notna()]\n",
    "\n",
    "# Drop columns because they're string vars or it's not quite interpretable to make a dummy var for every id \n",
    "to_drop = [\n",
    "    'party', 'base', 'country', 'cabinet_id', 'party_id', 'cabinet_name', \n",
    "    'party_name', 'party_name_english', 'country_id', 'election_id', \n",
    "    'election_date', 'start_date', 'post_election', 'lag_largest_parl', \n",
    "    'lag_largest_cab'\n",
    "]\n",
    "df_semi_dropped = df1.drop(columns=to_drop)\n",
    "\n",
    "# Identify columns with more than 15 missing values and drop them\n",
    "missing_values = df_semi_dropped.isna().sum()\n",
    "to_drop = missing_values[missing_values > 15].index\n",
    "df_dropped_initial = df_semi_dropped.drop(columns=to_drop)\n",
    "\n",
    "# **Convert Binary Columns to Numeric Before Calculating Mean and Std**\n",
    "binary_columns_initial = [\n",
    "    col for col in df_dropped_initial.columns \n",
    "    if df_dropped_initial[col].dropna().astype(str).isin(['0', '1']).all()\n",
    "]\n",
    "for col in binary_columns_initial:\n",
    "    df_dropped_initial[col] = df_dropped_initial[col].astype(int)\n",
    "\n",
    "# **Calculate Mean and Std Before Removing Missing Entries and Outliers**\n",
    "# Select only numeric columns for mean and std calculation\n",
    "numeric_columns = df_dropped_initial.select_dtypes(include=[np.number]).columns\n",
    "mean_before = df_dropped_initial[numeric_columns].mean()\n",
    "std_before = df_dropped_initial[numeric_columns].std()\n",
    "\n",
    "# **Remove rows with any remaining missing values**\n",
    "df_dropped_no_na = df_dropped_initial.dropna()\n",
    "\n",
    "# Function to remove rows with outliers\n",
    "def remove_outliers(df, threshold=10):\n",
    "    # Identify binary columns and convert to integers (if not already)\n",
    "    binary_columns = [\n",
    "        col for col in df.columns \n",
    "        if df[col].dropna().astype(str).isin(['0', '1']).all()\n",
    "    ]\n",
    "    for col in binary_columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "    \n",
    "    # Re-select numeric columns after conversion\n",
    "    numeric_df = df.select_dtypes(include='number')\n",
    "    \n",
    "    # Calculate mean and standard deviation for numeric columns\n",
    "    means = numeric_df.mean()\n",
    "    stds = numeric_df.std()\n",
    "    \n",
    "    # Create a mask for rows that are within the threshold for all numeric columns\n",
    "    mask = (numeric_df - means).abs() <= (threshold * stds)\n",
    "    valid_rows = mask.all(axis=1)\n",
    "    \n",
    "    # Return the cleaned DataFrame (retain all original columns)\n",
    "    return df[valid_rows]\n",
    "\n",
    "# **Remove Outliers**\n",
    "df_dropped_cleaned = remove_outliers(df_dropped_no_na, threshold=10)\n",
    "\n",
    "# **Calculate Mean and Std After Removing Missing Entries and Outliers**\n",
    "mean_after = df_dropped_cleaned[numeric_columns].mean()\n",
    "std_after = df_dropped_cleaned[numeric_columns].std()\n",
    "\n",
    "# **Compute the Change in Mean and Std**\n",
    "delta_mean = mean_after - mean_before\n",
    "delta_std = std_after - std_before\n",
    "\n",
    "# **Create a Summary DataFrame of Changes**\n",
    "stats_changes = pd.DataFrame({\n",
    "    'Mean_Before_Cleaning': mean_before,\n",
    "    'Mean_After_Cleaning': mean_after,\n",
    "    'Delta_Mean': delta_mean,\n",
    "    'Std_Before_Cleaning': std_before,\n",
    "    'Std_After_Cleaning': std_after,\n",
    "    'Delta_Std': delta_std\n",
    "})\n",
    "\n",
    "\n",
    "# **Print the Summary of Changes**\n",
    "print(\"Changes in Mean and Standard Deviation Before and After Cleaning:\\n\")\n",
    "print(stats_changes)\n",
    "\n",
    "# --------------------------------------------Standardization and Final Output--------------------------------------------------------\n",
    "\n",
    "# Define binary variables\n",
    "binary_variables = [\n",
    "    'sq_cabinet', 'sq_pm', 'caretaker', 'cabinet_party', 'prime_minister', 'mingov', \n",
    "    'bicameral', 'largest_parl', 'largest_cab', \n",
    "    'A', 'B', 'B_star', 'C', 'D', 'E', \n",
    "    'country_dummy1', 'country_dummy2', 'country_dummy3', 'country_dummy4', \n",
    "    'country_dummy5', 'country_dummy6', 'country_dummy7', 'country_dummy8', \n",
    "    'country_dummy9', 'country_dummy10', 'country_dummy11', 'country_dummy12', \n",
    "    'country_dummy13'\n",
    "]\n",
    "\n",
    "# **Ensure that all binary variables exist in the cleaned DataFrame**\n",
    "existing_binary_vars = [var for var in binary_variables if var in df_dropped_cleaned.columns]\n",
    "\n",
    "# **Separate the binary and non-binary data**\n",
    "binary_data = df_dropped_cleaned[existing_binary_vars]\n",
    "non_binary_data = df_dropped_cleaned.drop(columns=existing_binary_vars)\n",
    "\n",
    "# **Additions Start: Exclude 'cabinet_proportion' from standardization**\n",
    "# Extract 'cabinet_proportion' to exclude it from standardization\n",
    "cabinet_proportion = non_binary_data['cabinet_proportion']\n",
    "# Drop 'cabinet_proportion' from non_binary_data\n",
    "non_binary_data = non_binary_data.drop(columns=['cabinet_proportion'])\n",
    "# **Additions End**\n",
    "\n",
    "# **Standardize the non-binary data**\n",
    "scaler = StandardScaler()\n",
    "standardized_array = scaler.fit_transform(non_binary_data)\n",
    "standardized_data = pd.DataFrame(standardized_array, columns=non_binary_data.columns)\n",
    "\n",
    "# **Additions Start: Reattach 'cabinet_proportion' after standardization**\n",
    "# Add 'cabinet_proportion' back to the standardized data\n",
    "standardized_data['cabinet_proportion'] = cabinet_proportion.reset_index(drop=True)\n",
    "# **Additions End**\n",
    "\n",
    "# **Reset the index of both DataFrames to ensure alignment**\n",
    "standardized_data.reset_index(drop=True, inplace=True)\n",
    "binary_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# **Now concatenate**\n",
    "df_dropped = pd.concat([standardized_data, binary_data], axis=1)\n",
    "\n",
    "# **Optional:** Verify the final row count and alignment\n",
    "print(f\"\\nFinal dataset shape: {df_dropped.shape}\")  # Corrected variable from df_final to df_dropped\n",
    "\n",
    "# Save the final standardized and combined dataset to CSV\n",
    "df_dropped.to_csv('/Users/jz/Desktop/ML Final/output.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "018b3dac-39ef-4f02-9d36-dfe9d7038ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------PCA-------------------------------------------------------------\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def myPCA(merge_vars, merge_dim, data_frame, latent_description):\n",
    "    \"\"\"\n",
    "    Perform PCA on specified variables and return the PCA object along with the updated DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    - merge_vars: List of variable names to be merged.\n",
    "    - merge_dim: Number of latent variables after merge.\n",
    "    - data_frame: The DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "    - pca: Fitted PCA object.\n",
    "    - latent_df: DataFrame with only the PCA variables.\n",
    "    \n",
    "    \"\"\"\n",
    "    # Ensure all merge_vars exist in the DataFrame\n",
    "    missing_vars = [var for var in merge_vars if var not in data_frame.columns]\n",
    "    if missing_vars:\n",
    "        raise KeyError(f\"The following columns are missing in the DataFrame: {missing_vars}\")\n",
    "\n",
    "    # Extract data for PCA\n",
    "    data = data_frame[merge_vars].values\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=merge_dim)\n",
    "    latent_vars = pca.fit_transform(data)\n",
    "\n",
    "    # Create a DataFrame for latent variables\n",
    "    latent_df = pd.DataFrame(latent_vars, columns=[f'latent_var_{i+1} for {latent_description}' for i in range(merge_dim)], index=data_frame.index)\n",
    "\n",
    "\n",
    "    return pca, latent_df, data_frame\n",
    "\n",
    "\n",
    "import math\n",
    "\n",
    "def top_variables_by_latent(pca, variables, total_vars): #works as interpretor\n",
    "    \"\"\"\n",
    "    Given a PCA object and a list of original variable names, \n",
    "    returns a formatted string of the top original variables \n",
    "    and the variance explained for each variable in each latent variable (principal component).\n",
    "    \n",
    "    Parameters:\n",
    "    - pca: the fitted PCA object\n",
    "    - variables: list of original variable names used in PCA\n",
    "    - total_vars: total number of original variables\n",
    "    \n",
    "    Returns:\n",
    "    - A formatted string listing the top variables with their variance explained for each principal component.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store formatted strings for each component\n",
    "    result = []\n",
    "    \n",
    "    # Calculate the threshold for selecting top variables based on explained variance\n",
    "    threshold_fraction = 1 / total_vars\n",
    "    \n",
    "    # Create a DataFrame of the absolute loadings for easier manipulation\n",
    "    loadings = pd.DataFrame(np.abs(pca.components_), columns=variables)\n",
    "    \n",
    "    # Loop over each principal component\n",
    "    for i, explained_variance in enumerate(pca.explained_variance_ratio_):\n",
    "        # Calculate the number of top variables to select based on explained variance\n",
    "        num_top_vars = math.ceil(explained_variance / threshold_fraction)\n",
    "        \n",
    "        # Get the top variables for this principal component by sorting loadings\n",
    "        component_loadings = loadings.iloc[i]\n",
    "        top_variables = component_loadings.nlargest(num_top_vars + 2).index.tolist()\n",
    "        \n",
    "        # Format each top variable with its variance explained in the current component\n",
    "        variable_info = []\n",
    "        for var in top_variables:\n",
    "            var_loading = component_loadings[var]\n",
    "            var_variance_explained = var_loading  # Approximate variance explained\n",
    "            variable_info.append(f\"{var} ({var_variance_explained:.2%})\")\n",
    "        \n",
    "        # Format the result for this component\n",
    "        component_str = f\"PC{i+1} ({explained_variance:.2%} total variance explained): \" + \", \".join(variable_info)\n",
    "        result.append(component_str)\n",
    "    \n",
    "    # Join all component strings with new lines for a final formatted output\n",
    "    return \"\\n\\n\".join(result)\n",
    "    \n",
    "# Example usage:\n",
    "# formatted_string = top_variables_by_latent(pca2, merge_var, len(merge_var))\n",
    "# print(formatted_string)\n",
    "df_final.to_csv('/Users/jz/Desktop/ML Final/output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "82a0fc44-a8ae-4246-b9f8-cc088e0c04a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by each latent variable in PCA:  [0.5251645  0.28602597] [0.5251645  0.81119047] in 0.16666666666666666 threshold for loadings\n",
      "Variables to be dropped based on loadings threshold: ['seats', 'cabinet_seats', 'total_cabinet_size', 'seats_share', 'seats_total', 'seats_proportion']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seats</th>\n",
       "      <th>cabinet_seats</th>\n",
       "      <th>total_cabinet_size</th>\n",
       "      <th>seats_share</th>\n",
       "      <th>seats_total</th>\n",
       "      <th>seats_proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.460831</td>\n",
       "      <td>0.447505</td>\n",
       "      <td>0.040247</td>\n",
       "      <td>0.537872</td>\n",
       "      <td>0.051398</td>\n",
       "      <td>0.542039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.278169</td>\n",
       "      <td>0.009861</td>\n",
       "      <td>0.637976</td>\n",
       "      <td>0.129442</td>\n",
       "      <td>0.696205</td>\n",
       "      <td>0.118552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        seats  cabinet_seats  total_cabinet_size  seats_share  seats_total  \\\n",
       "PC1  0.460831       0.447505            0.040247     0.537872     0.051398   \n",
       "PC2  0.278169       0.009861            0.637976     0.129442     0.696205   \n",
       "\n",
       "     seats_proportion  \n",
       "PC1          0.542039  \n",
       "PC2          0.118552  "
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables to be merged and perform PCA1\n",
    "\n",
    "merge_var = ['seats', 'cabinet_seats', 'total_cabinet_size','seats_share', \n",
    "             'seats_total', 'seats_proportion']\n",
    "\n",
    "pca2, new_df, df_dropped = myPCA(merge_var, 2, df_dropped, 'population_based_party_influence')\n",
    "\n",
    "threshold = 1 / len(merge_var)\n",
    "print(\"Variance explained by each latent variable in PCA: \", pca2.explained_variance_ratio_,\n",
    "      pca2.explained_variance_ratio_.cumsum(), f'in {threshold} threshold for loadings')\n",
    "\n",
    "# Calculate the absolute loadings of each component for each variable\n",
    "loadings = pd.DataFrame(\n",
    "    np.abs(pca2.components_),\n",
    "    columns=merge_var,\n",
    "    index=[f'PC{i+1}' for i in range(pca2.n_components_)]\n",
    ")\n",
    "\n",
    "# Identify variables to drop based on the threshold\n",
    "vars_to_drop = loadings.columns[(loadings >= threshold).any(axis=0)]\n",
    "print(\"Variables to be dropped based on loadings threshold:\", vars_to_drop.tolist())\n",
    "\n",
    "# Drop only those identified variables from df_dropped\n",
    "df_dropped = df_dropped.drop(columns=vars_to_drop)\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "eb6f46e9-e53c-4cba-b841-4113dc5384f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance explained by each latent variable in PCA:  [0.47620343 0.27199895 0.11307971] [0.47620343 0.74820238 0.86128209] in 0.1111111111111111 threshold for loadings\n",
      "Variables to be dropped based on loadings threshold: ['miw_new', 'banzhaf', 'shapley', 'splus', 'party_count', 'cab_count', 'enpp', 'miw_proportion', 'W']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>miw_new</th>\n",
       "      <th>banzhaf</th>\n",
       "      <th>shapley</th>\n",
       "      <th>splus</th>\n",
       "      <th>party_count</th>\n",
       "      <th>cab_count</th>\n",
       "      <th>enpp</th>\n",
       "      <th>miw_proportion</th>\n",
       "      <th>W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.459681</td>\n",
       "      <td>0.462471</td>\n",
       "      <td>0.460956</td>\n",
       "      <td>0.254834</td>\n",
       "      <td>0.180730</td>\n",
       "      <td>0.201702</td>\n",
       "      <td>0.465262</td>\n",
       "      <td>0.086824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.500781</td>\n",
       "      <td>0.171032</td>\n",
       "      <td>0.171958</td>\n",
       "      <td>0.170710</td>\n",
       "      <td>0.477333</td>\n",
       "      <td>0.437533</td>\n",
       "      <td>0.345182</td>\n",
       "      <td>0.126240</td>\n",
       "      <td>0.326933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>0.058425</td>\n",
       "      <td>0.054769</td>\n",
       "      <td>0.051265</td>\n",
       "      <td>0.049668</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.023710</td>\n",
       "      <td>0.625461</td>\n",
       "      <td>0.013498</td>\n",
       "      <td>0.770369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      miw_new   banzhaf   shapley     splus  party_count  cab_count      enpp  \\\n",
       "PC1  0.006302  0.459681  0.462471  0.460956     0.254834   0.180730  0.201702   \n",
       "PC2  0.500781  0.171032  0.171958  0.170710     0.477333   0.437533  0.345182   \n",
       "PC3  0.058425  0.054769  0.051265  0.049668     0.055472   0.023710  0.625461   \n",
       "\n",
       "     miw_proportion         W  \n",
       "PC1        0.465262  0.086824  \n",
       "PC2        0.126240  0.326933  \n",
       "PC3        0.013498  0.770369  "
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the variables to be merged and perform PCA2\n",
    "\n",
    "merge_var = ['miw_new', 'banzhaf', 'shapley','splus', \n",
    "             'party_count', 'cab_count','enpp','miw_proportion','W']\n",
    "\n",
    "pca2, new_df2, df_dropped = myPCA(merge_var, 3, df_dropped, 'party_pivitality')\n",
    "\n",
    "threshold = 1 / len(merge_var)\n",
    "print(\"Variance explained by each latent variable in PCA: \", pca2.explained_variance_ratio_,\n",
    "      pca2.explained_variance_ratio_.cumsum(), f'in {threshold} threshold for loadings')\n",
    "\n",
    "# Calculate the absolute loadings of each component for each variable\n",
    "loadings = pd.DataFrame(\n",
    "    np.abs(pca2.components_),\n",
    "    columns=merge_var,\n",
    "    index=[f'PC{i+1}' for i in range(pca2.n_components_)]\n",
    ")\n",
    "\n",
    "# Identify variables to drop based on the threshold\n",
    "vars_to_drop = loadings.columns[(loadings >= threshold).any(axis=0)]\n",
    "print(\"Variables to be dropped based on loadings threshold:\", vars_to_drop.tolist())\n",
    "\n",
    "# Drop only those identified variables from df_dropped\n",
    "df_dropped = df_dropped.drop(columns=vars_to_drop)\n",
    "loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "8a93e056-2570-443c-8767-1728c821a6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to /Users/jz/Desktop/ML Final/output.csv\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------------------------------Training-------------------------------------------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LassoCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor \n",
    "\n",
    "# Data preparation\n",
    "Y = df_dropped['cabinet_proportion']\n",
    "X = df_dropped.drop(columns=['cabinet_proportion'])\n",
    "X = pd.concat([X, new_df, new_df2], axis=1)  # Merge all latent variables\n",
    "\n",
    "# Save the dataset to a CSV file\n",
    "output_path = '/Users/jz/Desktop/ML Final/output.csv'\n",
    "pd.concat([Y, X], axis=1).to_csv(output_path, index=False)\n",
    "print(f\"Data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "bd459a97-f471-439c-860e-10edf7a34c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Model Type: Lasso linear\n",
      "Best Alpha: 0.001\n",
      "Cross-Validated MSE: 0.0068\n",
      "\n",
      "Processing Model Type: Lasso polynomial\n",
      "Best Alpha: 0.01\n",
      "Cross-Validated MSE: 0.0022\n",
      "\n",
      "Processing Model Type: Gradient boosting\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Cross-Validated MSE: 0.0018\n",
      "\n",
      "Processing Model Type: Decision tree\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "Cross-Validated MSE: 0.0078\n",
      "\n",
      "\n",
      "================================ Best Models Summary =================================\n",
      "\n",
      "Model Type: Lasso linear\n",
      "Cross-Validated MSE: 0.0068\n",
      "Parameters: {'alpha': 0.001}\n",
      "\n",
      "Intercept: 0.1300\n",
      "Coefficients (sorted by absolute value):\n",
      "                                              Feature  Coefficient\n",
      "4                                       cabinet_party     0.099130\n",
      "29  latent_var_1 for population_based_party_influence     0.076126\n",
      "9                                         largest_cab     0.044256\n",
      "31                  latent_var_1 for party_pivitality     0.033512\n",
      "5                                      prime_minister     0.032246\n",
      "32                  latent_var_2 for party_pivitality    -0.021310\n",
      "23                                     country_dummy8     0.019584\n",
      "8                                        largest_parl    -0.018896\n",
      "33                  latent_var_3 for party_pivitality    -0.017229\n",
      "1                                          sq_cabinet    -0.006323\n",
      "6                                              mingov     0.005148\n",
      "25                                    country_dummy10     0.005112\n",
      "16                                     country_dummy1    -0.004293\n",
      "0                                       election_year    -0.003747\n",
      "20                                     country_dummy5    -0.003355\n",
      "2                                               sq_pm    -0.002761\n",
      "3                                           caretaker     0.002171\n",
      "27                                    country_dummy12     0.001599\n",
      "21                                     country_dummy6     0.001538\n",
      "26                                    country_dummy11    -0.001234\n",
      "19                                     country_dummy4     0.000927\n",
      "7                                           bicameral     0.000838\n",
      "22                                     country_dummy7    -0.000657\n",
      "12                                             B_star     0.000229\n",
      "13                                                  C    -0.000017\n",
      "14                                                  D    -0.000000\n",
      "28                                    country_dummy13    -0.000000\n",
      "30  latent_var_2 for population_based_party_influence     0.000000\n",
      "24                                     country_dummy9    -0.000000\n",
      "10                                                  A     0.000000\n",
      "15                                                  E     0.000000\n",
      "11                                                  B     0.000000\n",
      "18                                     country_dummy3    -0.000000\n",
      "17                                     country_dummy2    -0.000000\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Model Type: Lasso polynomial\n",
      "Cross-Validated MSE: 0.0022\n",
      "Parameters: {'alpha': 0.01}\n",
      "\n",
      "Intercept: 0.1300\n",
      "Coefficients (sorted by absolute value):\n",
      "                                               Feature  Coefficient\n",
      "189  cabinet_party latent_var_1 for population_base...     0.097869\n",
      "164                                    cabinet_party^2     0.050653\n",
      "4                                        cabinet_party     0.048445\n",
      "191    cabinet_party latent_var_1 for party_pivitality     0.038104\n",
      "166                               cabinet_party mingov     0.011411\n",
      "..                                                 ...          ...\n",
      "215                     prime_minister country_dummy11     0.000000\n",
      "216                     prime_minister country_dummy12     0.000000\n",
      "217                     prime_minister country_dummy13     0.000000\n",
      "218  prime_minister latent_var_1 for population_bas...     0.000000\n",
      "628                latent_var_3 for party_pivitality^2    -0.000000\n",
      "\n",
      "[629 rows x 2 columns]\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Model Type: Gradient boosting\n",
      "Cross-Validated MSE: 0.0018\n",
      "Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "\n",
      "Feature Importances (sorted by absolute value):\n",
      "                                              Feature  Importance\n",
      "9                                         largest_cab    0.335526\n",
      "4                                       cabinet_party    0.321194\n",
      "29  latent_var_1 for population_based_party_influence    0.182020\n",
      "5                                      prime_minister    0.057671\n",
      "31                  latent_var_1 for party_pivitality    0.052354\n",
      "30  latent_var_2 for population_based_party_influence    0.014395\n",
      "6                                              mingov    0.010890\n",
      "32                  latent_var_2 for party_pivitality    0.009574\n",
      "33                  latent_var_3 for party_pivitality    0.005767\n",
      "19                                     country_dummy4    0.003152\n",
      "0                                       election_year    0.002118\n",
      "7                                           bicameral    0.000979\n",
      "26                                    country_dummy11    0.000731\n",
      "2                                               sq_pm    0.000704\n",
      "20                                     country_dummy5    0.000437\n",
      "11                                                  B    0.000427\n",
      "24                                     country_dummy9    0.000315\n",
      "18                                     country_dummy3    0.000297\n",
      "27                                    country_dummy12    0.000251\n",
      "3                                           caretaker    0.000235\n",
      "14                                                  D    0.000179\n",
      "25                                    country_dummy10    0.000150\n",
      "16                                     country_dummy1    0.000138\n",
      "13                                                  C    0.000103\n",
      "8                                        largest_parl    0.000096\n",
      "23                                     country_dummy8    0.000082\n",
      "1                                          sq_cabinet    0.000078\n",
      "17                                     country_dummy2    0.000052\n",
      "15                                                  E    0.000036\n",
      "22                                     country_dummy7    0.000018\n",
      "21                                     country_dummy6    0.000013\n",
      "12                                             B_star    0.000009\n",
      "28                                    country_dummy13    0.000009\n",
      "10                                                  A    0.000000\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n",
      "Model Type: Decision tree\n",
      "Cross-Validated MSE: 0.0078\n",
      "Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10}\n",
      "\n",
      "Feature Importances (sorted by absolute value):\n",
      "                                              Feature  Importance\n",
      "5                                      prime_minister    0.641390\n",
      "31                  latent_var_1 for party_pivitality    0.072376\n",
      "4                                       cabinet_party    0.069771\n",
      "29  latent_var_1 for population_based_party_influence    0.067913\n",
      "12                                             B_star    0.025640\n",
      "30  latent_var_2 for population_based_party_influence    0.015596\n",
      "16                                     country_dummy1    0.014692\n",
      "9                                         largest_cab    0.014597\n",
      "32                  latent_var_2 for party_pivitality    0.011694\n",
      "6                                              mingov    0.011505\n",
      "17                                     country_dummy2    0.007837\n",
      "1                                          sq_cabinet    0.007767\n",
      "14                                                  D    0.007498\n",
      "15                                                  E    0.006750\n",
      "33                  latent_var_3 for party_pivitality    0.005609\n",
      "11                                                  B    0.003531\n",
      "0                                       election_year    0.002777\n",
      "26                                    country_dummy11    0.002332\n",
      "24                                     country_dummy9    0.001971\n",
      "13                                                  C    0.001832\n",
      "8                                        largest_parl    0.001618\n",
      "25                                    country_dummy10    0.001526\n",
      "21                                     country_dummy6    0.001434\n",
      "20                                     country_dummy5    0.001301\n",
      "28                                    country_dummy13    0.000447\n",
      "7                                           bicameral    0.000363\n",
      "23                                     country_dummy8    0.000232\n",
      "19                                     country_dummy4    0.000000\n",
      "22                                     country_dummy7    0.000000\n",
      "18                                     country_dummy3    0.000000\n",
      "10                                                  A    0.000000\n",
      "27                                    country_dummy12    0.000000\n",
      "3                                           caretaker    0.000000\n",
      "2                                               sq_pm    0.000000\n",
      "\n",
      "---------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the models to test with scaling included\n",
    "model_configs = [\n",
    "    {\n",
    "        'type': 'lasso_linear', \n",
    "        'model': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lasso', LassoCV(\n",
    "                alphas=[0.0001, 0.001, 0.01, 0.1, 1, 10], \n",
    "                max_iter=50000,    # Increased max_iter for better convergence\n",
    "                tol=1e-3,          # Adjusted tolerance\n",
    "                cv=5, \n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'type': 'lasso_polynomial', \n",
    "        'model': Pipeline([\n",
    "            ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('lasso', LassoCV(\n",
    "                alphas=[0.01, 0.1, 1, 10], \n",
    "                max_iter=50000,    # Increased max_iter for better convergence\n",
    "                tol=1e-3,          # Adjusted tolerance\n",
    "                cv=5, \n",
    "                random_state=42\n",
    "            ))\n",
    "        ])\n",
    "    },\n",
    "    {\n",
    "        'type': 'gradient_boosting',\n",
    "        'model': GradientBoostingRegressor(random_state=42)\n",
    "    },\n",
    "    {\n",
    "        'type': 'decision_tree',  # New Decision Tree configuration\n",
    "        'model': DecisionTreeRegressor(random_state=42)\n",
    "    }\n",
    "]\n",
    "\n",
    "# Define the parameter grids\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Parameter grid for Decision Tree\n",
    "dt_param_grid = {\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize a dictionary to store the best models for each type\n",
    "best_models = {}\n",
    "\n",
    "# Define cross-validation strategy\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate through each model configuration\n",
    "for config in model_configs:\n",
    "    model_type = config['type']\n",
    "    model = config['model']\n",
    "    \n",
    "    print(f\"\\nProcessing Model Type: {model_type.replace('_', ' ').capitalize()}\")\n",
    "    \n",
    "    if model_type == 'gradient_boosting':\n",
    "        # Perform Grid Search for Gradient Boosting\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model, \n",
    "            param_grid=gb_param_grid, \n",
    "            scoring='neg_mean_squared_error', # this is the cv MSE\n",
    "            cv=cv, \n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X, Y)\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Cross-validated MSE\n",
    "        neg_mse = cross_val_score(\n",
    "            best_estimator, X, Y, \n",
    "            cv=cv, \n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mse = -neg_mse.mean()\n",
    "        \n",
    "        # Store the best model details\n",
    "        best_models[model_type] = {\n",
    "            'model': best_estimator,\n",
    "            'params': best_params,\n",
    "            'mse': mse,\n",
    "            'alpha': None  # No alpha for Gradient Boosting\n",
    "        }\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Cross-Validated MSE: {mse:.4f}\")\n",
    "        \n",
    "    elif model_type == 'decision_tree':  # Handling Decision Tree\n",
    "        # Perform Grid Search for Decision Tree\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=model,\n",
    "            param_grid=dt_param_grid,\n",
    "            scoring='neg_mean_squared_error', # this is the cv MSE\n",
    "            cv=cv,\n",
    "            verbose=1,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X, Y)\n",
    "        best_estimator = grid_search.best_estimator_\n",
    "        best_params = grid_search.best_params_\n",
    "        \n",
    "        # Cross-validated MSE\n",
    "        neg_mse = cross_val_score(\n",
    "            best_estimator, X, Y,\n",
    "            cv=cv,\n",
    "            scoring='neg_mean_squared_error', # this is the cv MSE\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mse = -neg_mse.mean()\n",
    "        \n",
    "        # Store the best model details\n",
    "        best_models[model_type] = {\n",
    "            'model': best_estimator,\n",
    "            'params': best_params,\n",
    "            'mse': mse,\n",
    "            'alpha': None  # No alpha for Decision Tree\n",
    "        }\n",
    "        print(f\"Best Parameters: {best_params}\")\n",
    "        print(f\"Cross-Validated MSE: {mse:.4f}\")\n",
    "        \n",
    "    elif 'lasso' in model_type:\n",
    "        # Fit the Lasso model using cross-validation to find the best alpha\n",
    "        model.fit(X, Y)\n",
    "        best_alpha = model.named_steps['lasso'].alpha_\n",
    "        \n",
    "        # Cross-validated MSE\n",
    "        neg_mse = cross_val_score(\n",
    "            model, X, Y, \n",
    "            cv=cv, \n",
    "            scoring='neg_mean_squared_error', # this is the cv MSE\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mse = -neg_mse.mean()\n",
    "        \n",
    "        # Store the best model details\n",
    "        best_models[model_type] = {\n",
    "            'model': model,\n",
    "            'params': {'alpha': best_alpha},\n",
    "            'mse': mse,\n",
    "            'alpha': best_alpha\n",
    "        }\n",
    "        print(f\"Best Alpha: {best_alpha}\")\n",
    "        print(f\"Cross-Validated MSE: {mse:.4f}\")\n",
    "        \n",
    "    else:\n",
    "        # For Linear and Polynomial models\n",
    "        # Cross-validated MSE\n",
    "        neg_mse = cross_val_score(\n",
    "            model, X, Y, \n",
    "            cv=cv, \n",
    "            scoring='neg_mean_squared_error',\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        mse = -neg_mse.mean()\n",
    "        \n",
    "        # Fit the model on the entire dataset\n",
    "        model.fit(X, Y)\n",
    "        \n",
    "        # Store the best model details\n",
    "        best_models[model_type] = {\n",
    "            'model': model,\n",
    "            'params': {},\n",
    "            'mse': mse,\n",
    "            'alpha': None\n",
    "        }\n",
    "        print(f\"Cross-Validated MSE: {mse:.4f}\")\n",
    "\n",
    "# Output Best Models Details\n",
    "print(\"\\n\\n================================ Best Models Summary =================================\\n\")\n",
    "for model_type, details in best_models.items():\n",
    "    print(f\"Model Type: {model_type.replace('_', ' ').capitalize()}\")\n",
    "    print(f\"Cross-Validated MSE: {details['mse']:.4f}\")\n",
    "    if details['params']:\n",
    "        print(f\"Parameters: {details['params']}\")\n",
    "    else:\n",
    "        print(\"Parameters: Default\")\n",
    "    \n",
    "    if model_type in ['gradient_boosting', 'decision_tree']:\n",
    "        # Feature Importance for Tree-based models\n",
    "        feature_importance = details['model'].feature_importances_\n",
    "        feature_names = X.columns\n",
    "        importance_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Importance': feature_importance\n",
    "        })\n",
    "        # Sort by absolute importance\n",
    "        importance_df['Abs_Importance'] = importance_df['Importance'].abs()\n",
    "        importance_df = importance_df.sort_values(by='Abs_Importance', ascending=False).drop(columns=['Abs_Importance'])\n",
    "        print(\"\\nFeature Importances (sorted by absolute value):\")\n",
    "        print(importance_df)\n",
    "    \n",
    "    elif 'lasso' in model_type:\n",
    "        # Coefficients for Lasso models\n",
    "        if 'polynomial' in model_type:\n",
    "            poly = details['model'].named_steps['poly']\n",
    "            feature_names = poly.get_feature_names_out(X.columns)\n",
    "        else:\n",
    "            feature_names = X.columns\n",
    "        coefficients = details['model'].named_steps['lasso'].coef_\n",
    "        intercept = details['model'].named_steps['lasso'].intercept_\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': coefficients\n",
    "        })\n",
    "        # Sort by absolute coefficient value\n",
    "        coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "        coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n",
    "        print(f\"\\nIntercept: {intercept:.4f}\")\n",
    "        print(\"Coefficients (sorted by absolute value):\")\n",
    "        print(coef_df)\n",
    "    \n",
    "    else:\n",
    "        # Coefficients for Linear and Polynomial models\n",
    "        if model_type == 'polynomial':\n",
    "            poly = details['model'].named_steps['poly']\n",
    "            feature_names = poly.get_feature_names_out(X.columns)\n",
    "        else:\n",
    "            feature_names = X.columns\n",
    "        coefficients = details['model'].named_steps['linear'].coef_\n",
    "        intercept = details['model'].named_steps['linear'].intercept_\n",
    "        coef_df = pd.DataFrame({\n",
    "            'Feature': feature_names,\n",
    "            'Coefficient': coefficients\n",
    "        })\n",
    "        # Sort by absolute coefficient value\n",
    "        coef_df['Abs_Coefficient'] = coef_df['Coefficient'].abs()\n",
    "        coef_df = coef_df.sort_values(by='Abs_Coefficient', ascending=False).drop(columns=['Abs_Coefficient'])\n",
    "        print(f\"\\nIntercept: {intercept:.4f}\")\n",
    "        print(\"Coefficients (sorted by absolute value):\")\n",
    "        print(coef_df)\n",
    "    \n",
    "    print(\"\\n---------------------------------------------------------------------------------------\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "0c4634ed-dc53-48b8-acc2-107afbc540c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models summary saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "# save the best model summary to CSV\n",
    "\n",
    "summary = []\n",
    "for model_type, details in best_models.items():\n",
    "    entry = {\n",
    "        'Model Type': model_type,\n",
    "        'MSE': details['mse'],\n",
    "        'Hyperparameters': details['params']\n",
    "    }\n",
    "    summary.append(entry)\n",
    "summary_df = pd.DataFrame(summary)\n",
    "summary_df.to_csv('/Users/jz/Desktop/ML Final/best_models_summary.csv', index=False)\n",
    "print(\"Best models summary saved to CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec1047-2d06-49fe-ad7c-7329c355b1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
